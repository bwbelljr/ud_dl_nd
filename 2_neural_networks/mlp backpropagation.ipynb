{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "## Implementing in NumPy\n",
    "\n",
    "Previously we were only dealing with error terms from one unit. Now, in the weight update, we have to consider the error unit for *each unit* in the hidden layer, $\\delta_j$: $$\\Delta w_{ij} = \\eta \\delta_j x_i$$. Firstly, there will likely be a different number of input and hidden units, so trying to multiply the errors and the inputs as row vectors will throw an error.\n",
    "\n",
    "Also, $w_{ij}$ is a matrix now, so the right side of the assignment must have the same shape as the left side. NumPy takes care of this for us. If you multiply a row vector array with a column vector array, it will multiply the first element in the column by each element in the row vector and set that as the first row in a new 2D array. This continues for each element in the column vector, so you get a 2D array that has shape `(len(column_vector), len(row_vector))`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0e-02, 2.0e-03, 4.0e-05],\n",
       "       [2.0e-02, 4.0e-03, 8.0e-05],\n",
       "       [3.0e-02, 6.0e-03, 1.2e-04],\n",
       "       [4.0e-02, 8.0e-03, 1.6e-04],\n",
       "       [5.0e-02, 1.0e-02, 2.0e-04],\n",
       "       [6.0e-02, 1.2e-02, 2.4e-04]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating random arrays\n",
    "hidden_error = np.array([.1, .02, .0004])\n",
    "inputs = np.array([.1, .2, .3, .4, .5, .6])\n",
    "\n",
    "hidden_error * inputs[:, None] # has shape len(hidden_error), len(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out this is exactly how we want to calculate the weight update step. As before, if you have your inputs as a 2D array with one row, you can also do `hidden_error*inputs.T`, but that will not work if `inputs` is a 1D array.\n",
    "\n",
    "# Backpropagation exercise\n",
    "Below, you will implement the code to calculate one backpropagation update step for two sets of weights. The forward pass code is written - the goal is to code the backward pass.\n",
    "\n",
    "Things to do:\n",
    "* Calculate the network's output error.\n",
    "* Calculate the output layer's error term.\n",
    "* Use backpropagation to calculate the hidden layer's error term.\n",
    "* Calculate the change in weights (the delta weights) that result from propagating the errors back through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Calculate sigmoid\"\"\"\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.5, 0.1, -0.2])\n",
    "target = 0.6\n",
    "learnrate = 0.5\n",
    "\n",
    "weights_input_hidden = np.array([[0.5, -0.6],\n",
    "                                 [0.1, -0.2],\n",
    "                                 [0.1, 0.7]])\n",
    "\n",
    "weights_hidden_output = np.array([0.1, -0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "hidden_layer_input = np.dot(x, weights_input_hidden)\n",
    "hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "output = sigmoid(output_layer_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in weights for hidden layer to output layer:\n",
      "[0.00804047 0.00555918]\n",
      "Change in weights for input layer to hidden layer:\n",
      "[[ 1.77005547e-04 -5.11178506e-04]\n",
      " [ 3.54011093e-05 -1.02235701e-04]\n",
      " [-7.08022187e-05  2.04471402e-04]]\n"
     ]
    }
   ],
   "source": [
    "# Backward pass\n",
    "# TODO: Calculate output error\n",
    "error = target - output\n",
    "\n",
    "# TODO: Calculate error term for output layer\n",
    "output_error_term = error * output * (1-output)\n",
    "\n",
    "# TODO: Calculate error term for hidden layer\n",
    "hidden_error_term = weights_hidden_output*output_error_term*hidden_layer_output*(1-hidden_layer_output)\n",
    "\n",
    "# TODO: Calculate change in weights for hidden layer to output layer\n",
    "delta_w_h_o = learnrate*output_error_term*hidden_layer_output\n",
    "\n",
    "# TODO: Calculate change in weights for input layer to hidden layer\n",
    "delta_w_i_h = learnrate*hidden_error_term*x[:, None]\n",
    "\n",
    "print(\"Change in weights for hidden layer to output layer:\")\n",
    "print(delta_w_h_o)\n",
    "print(\"Change in weights for input layer to hidden layer:\")\n",
    "print(delta_w_i_h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ud_dl_nd] *",
   "language": "python",
   "name": "conda-env-ud_dl_nd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
