{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"part_8_transfer_learning.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPR+5qqzCPGCYo+cV9ZZj0i"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qliR2qG2xKt4"},"source":["# Transfer Learning\n","\n","We will use pre-trained networks to solve challenging problems in computer vision. Specifically, we will use networks trained on [ImageNet](http://www.image-net.org/) [available from torchvision](http://pytorch.org/docs/stable/torchvision/models.html).\n","\n","ImageNet is a massive dataset with over 1 million labeled images in 1000 categories. It is used to train deep neural networks using an architecture called convolutional layers.\n","\n","Once trained, these models work astonishingly well as feature detectors for images they were not trained on. Using a pre-trained network on images not in the training set is called transfer learning. Here we will use transfer learning to train a network that can classify our cat and dog photos with near perfect accuracy.\n","\n","With `torchvision.models` you can download these pre-trained networks and use them in your application. We will include `models` in our imports now."]},{"cell_type":"code","metadata":{"id":"a4eGcqBU0G1b","executionInfo":{"status":"ok","timestamp":1606516226959,"user_tz":-60,"elapsed":3718,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}}},"source":["%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZG-lKNXs1ArV"},"source":["Most of the pretrained models require the input to be 224x224 images. We also need to match the normalization used when the models were trained. Each color channel was normalized separately, the means are `[0.485, 0.456, 0.406]` and the standard deviations are `[0.229, 0.224, 0.225]`. "]},{"cell_type":"code","metadata":{"id":"rfgoPYHw1X3T","executionInfo":{"status":"ok","timestamp":1606517504820,"user_tz":-60,"elapsed":723,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}}},"source":["# Uncomment these lines to download and unzip files as  directory\n","#!wget https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip\n","#!unzip Cat_Dog_data.zip"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"jqp3FK3u1htD","executionInfo":{"status":"ok","timestamp":1606516804899,"user_tz":-60,"elapsed":647,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}}},"source":["data_dir = 'Cat_Dog_data'\n","\n","# Define Transforms for the training data and testing data\n","train_transforms = transforms.Compose([transforms.RandomRotation(30),\n","                                       transforms.RandomResizedCrop(224),\n","                                       transforms.RandomHorizontalFlip(),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize([0.485, 0.456, 0.406],\n","                                                            [0.229, 0.224, 0.225])])\n","test_transforms = transforms.Compose([transforms.Resize(255),\n","                                      transforms.CenterCrop(224),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize([0.485, 0.456, 0.406],\n","                                                           [0.229, 0.224, 0.225])])\n","\n","# Pass transforms in here\n","train_data = datasets.ImageFolder(data_dir, transform=train_transforms)\n","test_data = datasets.ImageFolder(data_dir, transform=test_transforms)\n","\n","trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, \n","                                          shuffle=True)\n","testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sun9A7_V3Qoy"},"source":["We can load in a model such as `DenseNet`. Let's print out the model architecture so we can see what is going on."]},{"cell_type":"code","metadata":{"id":"LRCD7K-b3eNm","executionInfo":{"status":"ok","timestamp":1606517329525,"user_tz":-60,"elapsed":719,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}}},"source":["model = models.densenet121(pretrained=True)\n","#model"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"duL8GIgj3hXL"},"source":["This model is built out of two main parts, the features and the classifier. The features part is a stack of convolutional layers and overall works as a feature detector that can be fed into a classifier. The classifier part is a single fully-connected layer `(classifier): Linear(in_features=1024, out_features=1000)`. This layer was trained on the ImageNet dataset, so it will not work for our specific problem. That means we need to replace the classifier, but the features will work perfectly on their own. In general, pre-trained networks can be viewed as good feature detectors that can be used as the input for simple feed-forward classifiers."]},{"cell_type":"code","metadata":{"id":"An6shB6M4bZe","executionInfo":{"status":"ok","timestamp":1606517348430,"user_tz":-60,"elapsed":986,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}}},"source":["# Freeze parameters so we don't backprop through them\n","for param in model.parameters():\n","  param.requires_grad = False\n","\n","from collections import OrderedDict\n","\n","classifier = nn.Sequential(OrderedDict([\n","                          ('fc1', nn.Linear(1024, 500)),\n","                          ('relu', nn.ReLU()),\n","                          ('fc2', nn.Linear(500, 2)),\n","                          ('output', nn.LogSoftmax(dim=1))\n","                          ]))\n","\n","model.classifier = classifier"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EgCtZr545KAF"},"source":["With our model built, we need to train the classifier. However, now we are using a **really deep** neural network. If you try to train this on a CPU like normal, it will take a long, long time. Instead, we are going to use the GPU to do the calculations. The linear algebra computations are done in parallel on the GPU leading to 100x increased training speeds. It is also possible to train on multiple GPUs, further decreasing training time."]}]}