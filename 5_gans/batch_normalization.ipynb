{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"batch_normalization.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOiAQ+yzmT6kKtzXuDuDjge"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"fba5f6f888e947f7b207f147d98aff87":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_651ee7808d3b40e282a4339ca116a24b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b2d46f277c6d4079a16297cddc9a5d0b","IPY_MODEL_6a5df3ec93ca4c11b884d434590efe8a"]}},"651ee7808d3b40e282a4339ca116a24b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b2d46f277c6d4079a16297cddc9a5d0b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a58ff1d90cc5464aae75b0ba3494cc77","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7faeea66a2ca4e5caf5684802bf5c645"}},"6a5df3ec93ca4c11b884d434590efe8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d06f0df2d05942988568d3c65938b695","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9920512/? [00:20&lt;00:00, 1546111.99it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6e0808218fa04828abc14e583dbdcd2d"}},"a58ff1d90cc5464aae75b0ba3494cc77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7faeea66a2ca4e5caf5684802bf5c645":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d06f0df2d05942988568d3c65938b695":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6e0808218fa04828abc14e583dbdcd2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3bbffc061e5b448d94f0cf4561d0fa60":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b75131d6244e4e01b784ed8f8d232eb1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b6fc9e17c946472d9cb7628c130adfe6","IPY_MODEL_777129b1874a4c10bdbb32ceec0eb185"]}},"b75131d6244e4e01b784ed8f8d232eb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b6fc9e17c946472d9cb7628c130adfe6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a66796f61dde4706b2ef27120062405c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ab89cc9a59bd476688b885c4e03b3d6b"}},"777129b1874a4c10bdbb32ceec0eb185":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6a4b810a00aa4ab3804db16205f7d747","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 32768/? [00:02&lt;00:00, 13706.13it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c09b17611760487cbe13cf82dac59232"}},"a66796f61dde4706b2ef27120062405c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ab89cc9a59bd476688b885c4e03b3d6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6a4b810a00aa4ab3804db16205f7d747":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c09b17611760487cbe13cf82dac59232":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"34b9c6ea55a14638b05694908a32131e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fbcb0abb81b44db2b58229d14744172c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d1dc0b081c2043e08517625069052fa3","IPY_MODEL_5743ac5eb3204a7c9ad59c60fa141977"]}},"fbcb0abb81b44db2b58229d14744172c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d1dc0b081c2043e08517625069052fa3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ff1596dad7304aff8fab1b3c86827421","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_006c6d4efa1c4ca3b92ecdfa1610cd3f"}},"5743ac5eb3204a7c9ad59c60fa141977":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5fbbcfa78b4c48ec8b64d96fa8697d49","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1654784/? [00:01&lt;00:00, 953709.70it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_318dfe692a6b406993d5cf903574a427"}},"ff1596dad7304aff8fab1b3c86827421":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"006c6d4efa1c4ca3b92ecdfa1610cd3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5fbbcfa78b4c48ec8b64d96fa8697d49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"318dfe692a6b406993d5cf903574a427":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0bb93e5d2db8497fbd8c13a49b91bd47":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_739d21fa97174c01816591f416f88ab6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3b35ab351b384387926358deb0664ccc","IPY_MODEL_705bc0d32c5540568ecd028bd27572a8"]}},"739d21fa97174c01816591f416f88ab6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3b35ab351b384387926358deb0664ccc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0f04132d04db4082a0370e937cab1953","_dom_classes":[],"description":"  0%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_75fab20ca6dd45dc9c137b7c701165ab"}},"705bc0d32c5540568ecd028bd27572a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4907bdd5520842c886eec4b7b50af07b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/4542 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_22c56fa42cbe49b88ae41e1e13edc404"}},"0f04132d04db4082a0370e937cab1953":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"75fab20ca6dd45dc9c137b7c701165ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4907bdd5520842c886eec4b7b50af07b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"22c56fa42cbe49b88ae41e1e13edc404":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"ndmv3yyQUdgD"},"source":["# Batch Normalization\r\n","\r\n","Batch normalization was introduced in Sergey Ioffe's and Christian Szegedy's 2015 paper [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167.pdf). The idea is that instead of just normalizing the inputs to the network, we normalize the inputs to *layers within* the network.\r\n","\r\n",">It's called **batch** normalization because during training, we normalize each layer's inputs byusing the mean and variance of the values in the current *batch*.\r\n","\r\n","## Batch Normalization in PyTorch\r\n","\r\n","This section of the notebook shows you one way to add batch normalization to a neural network built in PyTorch.\r\n","\r\n","The following cells import the packages we need in the notebook and load the MNIST dataset to use in our experiments."]},{"cell_type":"code","metadata":{"id":"f1hnq9OIGTW5","executionInfo":{"status":"ok","timestamp":1612694879366,"user_tz":-60,"elapsed":982,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}}},"source":["%matplotlib inline\r\n","\r\n","import numpy as np\r\n","import torch\r\n","import matplotlib.pyplot as plt\r\n","\r\n","from torchvision import datasets\r\n","import torchvision.transforms as transforms"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":403,"referenced_widgets":["fba5f6f888e947f7b207f147d98aff87","651ee7808d3b40e282a4339ca116a24b","b2d46f277c6d4079a16297cddc9a5d0b","6a5df3ec93ca4c11b884d434590efe8a","a58ff1d90cc5464aae75b0ba3494cc77","7faeea66a2ca4e5caf5684802bf5c645","d06f0df2d05942988568d3c65938b695","6e0808218fa04828abc14e583dbdcd2d","3bbffc061e5b448d94f0cf4561d0fa60","b75131d6244e4e01b784ed8f8d232eb1","b6fc9e17c946472d9cb7628c130adfe6","777129b1874a4c10bdbb32ceec0eb185","a66796f61dde4706b2ef27120062405c","ab89cc9a59bd476688b885c4e03b3d6b","6a4b810a00aa4ab3804db16205f7d747","c09b17611760487cbe13cf82dac59232","34b9c6ea55a14638b05694908a32131e","fbcb0abb81b44db2b58229d14744172c","d1dc0b081c2043e08517625069052fa3","5743ac5eb3204a7c9ad59c60fa141977","ff1596dad7304aff8fab1b3c86827421","006c6d4efa1c4ca3b92ecdfa1610cd3f","5fbbcfa78b4c48ec8b64d96fa8697d49","318dfe692a6b406993d5cf903574a427","0bb93e5d2db8497fbd8c13a49b91bd47","739d21fa97174c01816591f416f88ab6","3b35ab351b384387926358deb0664ccc","705bc0d32c5540568ecd028bd27572a8","0f04132d04db4082a0370e937cab1953","75fab20ca6dd45dc9c137b7c701165ab","4907bdd5520842c886eec4b7b50af07b","22c56fa42cbe49b88ae41e1e13edc404"]},"id":"gkSiTcJOGlVb","executionInfo":{"status":"ok","timestamp":1612695144023,"user_tz":-60,"elapsed":6741,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}},"outputId":"e0aea575-7061-487d-f6a7-caf354f6904f"},"source":["# number of subprocesses to use for data loading\r\n","num_workers = 0\r\n","# how many samples per batch to load\r\n","batch_size = 64\r\n","\r\n","# convert data to torch.FloatTensor\r\n","transform = transforms.ToTensor()\r\n","\r\n","# get the training and test datasets\r\n","train_data = datasets.MNIST(root='data', train=True, transform=transform, \r\n","                            download=True)\r\n","\r\n","test_data = datasets.MNIST(root='data', train=False, transform=transform, \r\n","                           download=True)\r\n","\r\n","# prepare data loaders\r\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\r\n","                                           num_workers=num_workers)\r\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \r\n","                                          num_workers=num_workers)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fba5f6f888e947f7b207f147d98aff87","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3bbffc061e5b448d94f0cf4561d0fa60","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34b9c6ea55a14638b05694908a32131e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0bb93e5d2db8497fbd8c13a49b91bd47","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n","Processing...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"},{"output_type":"stream","text":["Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ODWfmA1FGsJF"},"source":["## Visualize the data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":229},"id":"vxHdiz1EH0W4","executionInfo":{"status":"ok","timestamp":1612695253631,"user_tz":-60,"elapsed":2236,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}},"outputId":"7cab0cd0-e160-4336-da77-7a4f0c29d268"},"source":["# obtain on batch of training images\r\n","dataiter = iter(train_loader)\r\n","images, labels = dataiter.next()\r\n","images = images.numpy()\r\n","\r\n","# get one image from the batch\r\n","img = np.squeeze(images[0])\r\n","\r\n","fig = plt.figure(figsize=(3,3))\r\n","ax = fig.add_subplot(111)\r\n","ax.imshow(img, cmap='gray')"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fbe9006ed30>"]},"metadata":{"tags":[]},"execution_count":5},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 216x216 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"Q45VLwS5IKlL"},"source":["## Neural network classes for testing\r\n","\r\n","The following class, `NeuralNet`, allows us to create identical neural networks **with and without batch normalization** to compare. The code is heavily documented, but there is also some additional discussion later...\r\n","\r\n","*About the code:*\r\n","> We are defining a simple MLP for classification; this design choice was made to support the discussion related to batch normalization and not to get the best classification accuracy.\r\n","\r\n","### (Important) Model Details\r\n","\r\n","We add batch normalization to layers inside the `__init__` function. Here are some important points about that code:\r\n","1. Layers with batch normalization do **not** include a bias term.\r\n","2. We use PyTorch's [BatchNorm1d](https://pytorch.org/docs/stable/nn.html#batchnorm1d) function to handle the math. This is the function you use to operate on linear layer outputs; you'll use [BatchNorm2d]() for 2D outputs like filtered images from convolutional layers.\r\n","3. We add the batch normalization layer *before* calling the activation function.\r\n"]},{"cell_type":"code","metadata":{"id":"fxeCWpkNJKyx","executionInfo":{"status":"ok","timestamp":1612695534171,"user_tz":-60,"elapsed":1498,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}}},"source":["import torch.nn as nn\r\n","import torch.nn.functional as F"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"4QEmelzrJPO6","executionInfo":{"status":"ok","timestamp":1612696322877,"user_tz":-60,"elapsed":906,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}}},"source":["class NeuralNet(nn.Module):\r\n","    def __init__(self, use_batch_norm, input_size=784, hidden_dim=256, \r\n","                 output_size=10):\r\n","        \"\"\"\r\n","        Creates a PyTorch net using the given parameters.\r\n","\r\n","        :param use_batch_norm: bool\r\n","            Pass True to create a network that uses batch normalization; False\r\n","            otherwise. Note: this network will not use batch normalization on \r\n","            layers that do not have an activation function.\r\n","        \"\"\"\r\n","\r\n","        super(NeuralNet, self).__init__() # init super\r\n","\r\n","        # Default layer sizes\r\n","        self.input_size = input_size # (28*28 images)\r\n","        self.hidden_dim = hidden_dim\r\n","        self.output_size = output_size # (number of classes)\r\n","        # keep track of whether or not this network using batch normalization\r\n","        self.use_batch_norm = use_batch_norm\r\n","\r\n","        # define hidden linear layers, with optional batch norm on their outputs\r\n","        # layers with batch_norm applied have no bias term\r\n","        if use_batch_norm:\r\n","            self.fc1 = nn.Linear(input_size, hidden_dim*2, bias=False)\r\n","            self.batch_norm1 = nn.BatchNorm1d(hidden_dim*2)\r\n","        else:\r\n","            self.fc1 = nn.Linear(input_size, hidden_dim*2)\r\n","\r\n","        # define *second* hidden linear layers, with optional batch norm on \r\n","        # their outputs\r\n","        if use_batch_norm:\r\n","            self.fc2 = nn.Linear(hidden_dim*2, hidden_dim, bias=False)\r\n","            self.batch_norm2 = nn.BatchNorm1d(hidden_dim)\r\n","        else:\r\n","            self.fc2 = nn.Linear(hidden_dim*2, hidden_dim)\r\n","\r\n","        # define final fully-connected layer\r\n","        self.fc3 = nn.Linear(hidden_dim, output_size)\r\n","\r\n","    def forward(self, x):\r\n","        # flatten image\r\n","        x = x.view(-1, 28*28)\r\n","        # all hidden layers + optional batch norm + relu activation\r\n","        x = self.fc1(x)\r\n","        if self.use_batch_norm:\r\n","            x = self.batch_norm1(x)\r\n","        x = F.relu(x)\r\n","        # second layer\r\n","        x = self.fc2(x)\r\n","        if self.use_batch_norm:\r\n","            x = self.batch_norm2(x)\r\n","        x = F.relu(x)\r\n","        # third layer, no batch norm or activation\r\n","        x = self.fc3(x)\r\n","        return x"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BR8FLXwBMP84"},"source":["### Create two different models for testing\r\n","\r\n","* `net_batchnorm` is a linear classification model **with** batch normalization applied to the output of its hidden layers.\r\n","* `net_no_norm` is a plain MLP, without batch normalization\r\n","\r\n","Besides the normalization layers, everything about these models is the same."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TRNiQOceMiBn","executionInfo":{"status":"ok","timestamp":1612696458607,"user_tz":-60,"elapsed":1006,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}},"outputId":"3393911c-83b1-4778-caa5-f97c48becec8"},"source":["net_batchnorm = NeuralNet(use_batch_norm=True)\r\n","net_no_norm = NeuralNet(use_batch_norm=False)\r\n","\r\n","print(net_batchnorm)\r\n","print()\r\n","print(net_no_norm)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["NeuralNet(\n","  (fc1): Linear(in_features=784, out_features=512, bias=False)\n","  (batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc2): Linear(in_features=512, out_features=256, bias=False)\n","  (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",")\n","\n","NeuralNet(\n","  (fc1): Linear(in_features=784, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=256, bias=True)\n","  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4CfoOyReMxEr"},"source":["---\r\n","## Training\r\n","\r\n","The below `train` function will take in a model and some number of epochs. We'll use cross entropy loss and stochastic gradient descent for optimization. This function returns the losses, recorded after each epoch, so that we can display and compare the behavior of different models.\r\n","\r\n","#### `.train()` mode\r\n","\r\n","Note that we tell our model whether or not it should be in training mode, `model.train()`. This is an important step because batch normalization has different behavior during training on a batch or testing/evaluating on a larger dataset."]},{"cell_type":"code","metadata":{"id":"BKtsObQsNavT","executionInfo":{"status":"ok","timestamp":1612698452970,"user_tz":-60,"elapsed":1991,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}}},"source":["def train(model, n_epochs=10):\r\n","    # number of epochs to train the model\r\n","    n_epochs = n_epochs\r\n","    # track losses\r\n","    losses = []\r\n","\r\n","    # optimization strategy\r\n","    # specify loss function (categorical cross-entropy)\r\n","    criterion = nn.CrossEntropyLoss()\r\n","\r\n","    # specify optimizer (stochastic gradient descent) and learning rate=0.01\r\n","    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\r\n","\r\n","    # set the model to training mode\r\n","    model.train()\r\n","\r\n","    for epoch in range(1, n_epochs+1):\r\n","        # monitor training loss\r\n","        train_loss = 0.0\r\n","\r\n","        ###################\r\n","        # train the model #\r\n","        ###################\r\n","        batch_count = 0\r\n","        for batch_idx, (data, target) in enumerate(train_loader):\r\n","            # clear the gradients of all optimized variables\r\n","            optimizer.zero_grad()\r\n","            # forward pass: compute predicted outputs by passing inputs to model\r\n","            output = model(data)\r\n","            # calculate the loss \r\n","            loss = criterion(output, target)\r\n","            # Perform backpropagation: compute gradient of loss wrt parameters\r\n","            loss.backward()\r\n","            # Optimization Step; parameter update\r\n","            optimizer.step()\r\n","            # update average training loss\r\n","            train_loss += loss.item()\r\n","            batch_count += 1\r\n","        \r\n","        # print training statistics\r\n","        losses.append(train_loss/batch_count)\r\n","        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\r\n","            epoch,\r\n","            train_loss/batch_count))\r\n","        \r\n","    # return all recorded batch losses\r\n","    return losses"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FDJKbedVUQLc"},"source":["### Comparing Models\r\n","\r\n","In the below cells, we train our two different models and compare their training loss over time."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"at1BQzRqUfeY","executionInfo":{"status":"ok","timestamp":1612698713146,"user_tz":-60,"elapsed":170483,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}},"outputId":"b9bdaa9b-ce52-4d77-d3cc-2e2062c84a44"},"source":["# batchnorm model losses\r\n","# this may take some time to train\r\n","losses_batchnorm = train(net_batchnorm)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Epoch: 1 \tTraining Loss: 0.392630\n","Epoch: 2 \tTraining Loss: 0.162420\n","Epoch: 3 \tTraining Loss: 0.112422\n","Epoch: 4 \tTraining Loss: 0.083627\n","Epoch: 5 \tTraining Loss: 0.064061\n","Epoch: 6 \tTraining Loss: 0.049748\n","Epoch: 7 \tTraining Loss: 0.038871\n","Epoch: 8 \tTraining Loss: 0.030500\n","Epoch: 9 \tTraining Loss: 0.024172\n","Epoch: 10 \tTraining Loss: 0.019327\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"76Um6-xOUmDG","executionInfo":{"status":"ok","timestamp":1612698818510,"user_tz":-60,"elapsed":274385,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}},"outputId":"afe2abb5-e53a-4fd8-f89d-9f9d58a8f157"},"source":["# *no* norm model losses\r\n","# you should already start to see a difference in training losses\r\n","losses_no_norm = train(net_no_norm)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Epoch: 1 \tTraining Loss: 1.565684\n","Epoch: 2 \tTraining Loss: 0.506904\n","Epoch: 3 \tTraining Loss: 0.376361\n","Epoch: 4 \tTraining Loss: 0.329634\n","Epoch: 5 \tTraining Loss: 0.300255\n","Epoch: 6 \tTraining Loss: 0.277496\n","Epoch: 7 \tTraining Loss: 0.258190\n","Epoch: 8 \tTraining Loss: 0.241128\n","Epoch: 9 \tTraining Loss: 0.225784\n","Epoch: 10 \tTraining Loss: 0.211976\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":516},"id":"W0_nZf3kUueP","executionInfo":{"status":"ok","timestamp":1612699896186,"user_tz":-60,"elapsed":1290,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}},"outputId":"a9715a3c-e097-428b-9f09-aaf4598e3bc1"},"source":["# compare\r\n","fig, ax = plt.subplots(figsize=(12,8))\r\n","#losses_batchnorm = np.array(losses_batchnorm)\r\n","#losses_no_norm = np.array(losses_no_norm)\r\n","plt.plot(losses_batchnorm, label='Using batchnorm', alpha=0.5)\r\n","plt.plot(losses_no_norm, label='No norm', alpha=0.5)\r\n","plt.title('Training losses')\r\n","plt.legend()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7fbe8f879048>"]},"metadata":{"tags":[]},"execution_count":14},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x576 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"zS4xWNG3Z4Pz"},"source":["---\r\n","## Testing\r\n","\r\n","You should see that the model with batch normalization starts off with a lower training loss and over 10 epochs of training, gets to a training loss that is noticeably lower than our model without normalization.\r\n","\r\n","Next, let's see how both these model perform on our test data! Below, we have a function `test` that takes in a model and a parameter `train` (True or False) which indicates whether the model should be in training or evaluation mode. This is for comparison purposes, later. This function will calculate some test statistics including the overall test accuracy of a passed in model."]},{"cell_type":"code","metadata":{"id":"dlaURo-maYzS","executionInfo":{"status":"ok","timestamp":1612700786975,"user_tz":-60,"elapsed":1262,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}}},"source":["def test(model, train):\r\n","    # initialize vars to monitor test loss and accuracy\r\n","    class_correct = list(0. for i in range(10))\r\n","    class_total = list(0. for i in range(10))\r\n","    test_loss = 0.0\r\n","\r\n","    # set model to train or evaluation mode\r\n","    # just to see the difference in behavior\r\n","    if(train==True):\r\n","        model.train()\r\n","    if(train==False):\r\n","        model.eval()\r\n","\r\n","    # loss criterion\r\n","    criterion = nn.CrossEntropyLoss()\r\n","\r\n","    for batch_idx, (data, target) in enumerate(test_loader):\r\n","        batch_size = data.size(0)\r\n","        # forward pass\r\n","        output = model(data)\r\n","        # compute loss\r\n","        loss = criterion(output, target)\r\n","        test_loss += loss.item()*batch_size\r\n","        # convert output proabilities to predicted class\r\n","        _, pred = torch.max(output, 1)\r\n","        # compare predictions to true label\r\n","        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\r\n","        # calculate test accuracy for each object class\r\n","        for i in range(batch_size):\r\n","            label = target.data[i]\r\n","            class_correct[label] += correct[i].item()\r\n","            class_total[label] += 1\r\n","\r\n","    print('Test Loss: {:.6f}\\n'.format(test_loss/len(test_loader.dataset)))\r\n","\r\n","    for i in range(10):\r\n","        if class_total[i] > 0:\r\n","            print('Test accuracy of %5s: %2d%% (%2d/%2d)' % (\r\n","                str(i), 100*class_correct[i] / class_total[i],\r\n","                np.sum(class_correct[i]), np.sum(class_total[i])))\r\n","        else:\r\n","            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\r\n","\r\n","    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\r\n","        100. * np.sum(class_correct) / np.sum(class_total),\r\n","        np.sum(class_correct), np.sum(class_total)))"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"av927V0ndRua"},"source":["### Training and Evaluation Mode\r\n","\r\n","Setting a model to evaluation mode is important for models with batch normalization layers.\r\n","\r\n",">* Training mode means that the batch normalization layers will use **batch** statistics to calculate the batch norm.\r\n",">* Evaluation model, on the other hand, uses the estimated **population** mean and variance from the enture training set, which should give us increased performance on this test data!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"63YfgbVndnxW","executionInfo":{"status":"ok","timestamp":1612700898172,"user_tz":-60,"elapsed":3101,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}},"outputId":"bb243030-75a1-41e5-dd85-9ac888a9531a"},"source":["# test batchnorm case, in *train* mode\r\n","test(net_batchnorm, train=True)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Test Loss: 0.082428\n","\n","Test accuracy of     0: 98% (969/980)\n","Test accuracy of     1: 99% (1125/1135)\n","Test accuracy of     2: 96% (999/1032)\n","Test accuracy of     3: 97% (989/1010)\n","Test accuracy of     4: 97% (956/982)\n","Test accuracy of     5: 97% (866/892)\n","Test accuracy of     6: 97% (933/958)\n","Test accuracy of     7: 97% (998/1028)\n","Test accuracy of     8: 96% (940/974)\n","Test accuracy of     9: 96% (970/1009)\n","\n","Test Accuracy (Overall): 97% (9745/10000)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RY10rDt7dscX","executionInfo":{"status":"ok","timestamp":1612700927988,"user_tz":-60,"elapsed":1984,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}},"outputId":"dc3b6954-601d-4da0-f48a-8e58344784a8"},"source":["# test batchnorm case, in *evaluation* mode\r\n","test(net_batchnorm, train=False)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Test Loss: 0.070114\n","\n","Test accuracy of     0: 98% (970/980)\n","Test accuracy of     1: 99% (1127/1135)\n","Test accuracy of     2: 97% (1007/1032)\n","Test accuracy of     3: 97% (988/1010)\n","Test accuracy of     4: 97% (954/982)\n","Test accuracy of     5: 98% (876/892)\n","Test accuracy of     6: 97% (933/958)\n","Test accuracy of     7: 96% (994/1028)\n","Test accuracy of     8: 95% (935/974)\n","Test accuracy of     9: 97% (983/1009)\n","\n","Test Accuracy (Overall): 97% (9767/10000)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"skRKw-usdz2l","executionInfo":{"status":"ok","timestamp":1612700964603,"user_tz":-60,"elapsed":2502,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}},"outputId":"6ec2d47e-4df1-4b30-84c1-567045bfd9f9"},"source":["# test no norm case in evaluation mode\r\n","test(net_no_norm, train=False)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Test Loss: 0.204393\n","\n","Test accuracy of     0: 98% (965/980)\n","Test accuracy of     1: 98% (1113/1135)\n","Test accuracy of     2: 91% (943/1032)\n","Test accuracy of     3: 92% (939/1010)\n","Test accuracy of     4: 93% (923/982)\n","Test accuracy of     5: 93% (831/892)\n","Test accuracy of     6: 94% (910/958)\n","Test accuracy of     7: 92% (954/1028)\n","Test accuracy of     8: 91% (891/974)\n","Test accuracy of     9: 93% (939/1009)\n","\n","Test Accuracy (Overall): 94% (9408/10000)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TsSGlWnxeIN6"},"source":["### Which model has the highest accuracy?\r\n","\r\n","You should see a small improvement when comparing the batch norm model's accuracy in training and evaluation mode; **evaluation mode** should give a small improvement!\r\n","\r\n","You should also see that the model that uses batch normalization layers shows a marked improvement in overall accuracy when compared with the no-normalization model.\r\n","\r\n","---\r\n","\r\n","## Considerations for other network types\r\n","\r\n","This notebook demonstrates batch normalization in a standard neural network with fully connected layers. You can also use batch normalization in other types of networks, but there are some special considerations.\r\n","\r\n","### ConvNets\r\n","Convolution leys consist of multiple feature maps. (Remember, the depth of a convolutional layer refers to its number of feature maps) And the weights for each filter map are shared across all the inputs that feed into the layer. Because of these differences, batch normalizing convolutional layers requires batch/population mean and variance per feature map rather than per node in the layer.\r\n","\r\n","> To apply batch normalization on the outputs of convolutional layers, we use [BatchNorm2d](https://pytorch.org/docs/stable/nn.html#batchnorm2d).\r\n","\r\n","### RNNs\r\n","Batch normalization can work with recurrent neural networks, as shown in the 2016 paper [Recurrent Batch Normalization](https://arxiv.org/abs/1603.09025). It's a bit more work to implement, but basically involves calculating the means and variances per time step instead of per layer. You can find an example where someone implemented recurrent batch normalization in PyTorch, in [this GitHub repo](https://github.com/jihunchoi/recurrent-batch-normalization-pytorch)."]}]}