{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cifar_cnn_exercise.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyODML9Rxuu1Srp1YVqzJ1vJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3d792d43ab9c43a98f939dca335479a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e0d1e41b9e6a4861ad326266f19433e5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_653d074fd3de4ab593781ea7c0c42335","IPY_MODEL_33f949f8d3ef44f49606200a385d2749"]}},"e0d1e41b9e6a4861ad326266f19433e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"653d074fd3de4ab593781ea7c0c42335":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0bdada7230ae41dbb699e914498a12c7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ab7df7c322de4eeda36227663a952545"}},"33f949f8d3ef44f49606200a385d2749":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2955311de2fd471dab0cd0e582020d76","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170500096/? [00:20&lt;00:00, 77287567.83it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_11e68b71d0d846e495bc5f3d7f8ba76f"}},"0bdada7230ae41dbb699e914498a12c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ab7df7c322de4eeda36227663a952545":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2955311de2fd471dab0cd0e582020d76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"11e68b71d0d846e495bc5f3d7f8ba76f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"5hqVC3LaMQ-8"},"source":["# Convolutional Neural Networks\r\n","---\r\n","In this notebook, we train a **CNN** to classify images from the CIFAR-10 database.\r\n","\r\n","The images in this database are small color images that fall into one of ten classes; some example images are pictured below.\r\n","\r\n","<img src='https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/convolutional-neural-networks/cifar-cnn/notebook_ims/cifar_data.png' height=70% width=70% />"]},{"cell_type":"markdown","metadata":{"id":"x58ZNlKFNiuu"},"source":["### Test for [CUDA](http://pytorch.org/docs/stable/cuda.html)\r\n","\r\n","Since these are larger (32x32x3) images, it may be useful to speed up your training time by using a GPU. CUDA is a parallel computing platform and CUDA Tensors are the same as typical Tensors, only they utilize GPU's for computation."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tJpHToQeOBE1","executionInfo":{"status":"ok","timestamp":1607546269899,"user_tz":-60,"elapsed":4702,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}},"outputId":"474ebed0-6ae4-4319-8b5d-411dc26a7185"},"source":["import torch\r\n","import numpy as np\r\n","\r\n","# check if CUDA is available\r\n","train_on_gpu = torch.cuda.is_available()\r\n","\r\n","if not train_on_gpu:\r\n","  print('CUDA is not available. Training on CPU ...')\r\n","else:\r\n","  print('CUDA is available! Training on GPU ...')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["CUDA is not available. Training on CPU ...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VBNE1iVDOTZR"},"source":["---\r\n","## Load the [Data](http://pytorch.org/docs/stable/torchvision/datasets.html)\r\n","\r\n","Downloading may take a minute. We load in the training and test data, split the training data into a training and validation set, then create DataLoaders for each of these sets of data."]},{"cell_type":"code","metadata":{"id":"3hF7jQIqOxdw","executionInfo":{"status":"ok","timestamp":1607546424950,"user_tz":-60,"elapsed":556,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}}},"source":["from torchvision import datasets\r\n","import torchvision.transforms as transforms\r\n","from torch.utils.data.sampler import SubsetRandomSampler"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":120,"referenced_widgets":["3d792d43ab9c43a98f939dca335479a6","e0d1e41b9e6a4861ad326266f19433e5","653d074fd3de4ab593781ea7c0c42335","33f949f8d3ef44f49606200a385d2749","0bdada7230ae41dbb699e914498a12c7","ab7df7c322de4eeda36227663a952545","2955311de2fd471dab0cd0e582020d76","11e68b71d0d846e495bc5f3d7f8ba76f"]},"id":"xHAhwUNfO8wD","executionInfo":{"status":"ok","timestamp":1607547137000,"user_tz":-60,"elapsed":7565,"user":{"displayName":"Bob Bell","photoUrl":"","userId":"12813757050463534657"}},"outputId":"d8c28058-1123-4a67-d690-559484441768"},"source":["# number of subprocesses to use for data loading\r\n","num_workers = 0\r\n","# how many samples per batch to load\r\n","batch_size = 20\r\n","# percentage of training set to use as validation\r\n","valid_size = 0.2\r\n","\r\n","# convert data to a normalized torch.FloatTensor\r\n","transform = transforms.Compose([\r\n","      transforms.ToTensor(),\r\n","      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\r\n","])\r\n","\r\n","# choose the training and test datasets\r\n","train_data = datasets.CIFAR10('data', train=True, download=True, \r\n","                              transform=transform)\r\n","test_data = datasets.CIFAR10('data', train=False, download=True,\r\n","                             transform=transform)\r\n","\r\n","# obtain training indices that will be used fgor validation\r\n","num_train = len(train_data)\r\n","indices = list(range(num_train))\r\n","np.random.shuffle(indices)\r\n","split = int(np.floor(valid_size*num_train))\r\n","train_idx, valid_idx = indices[split:], indices[:split]\r\n","\r\n","# define samplers for obtaining training and validation batches\r\n","train_sampler = SubsetRandomSampler(train_idx)\r\n","valid_sampler = SubsetRandomSampler(valid_idx)\r\n","\r\n","# prepare data loaders (combine dataset and sampler)\r\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\r\n","                                sampler=train_sampler, num_workers=num_workers)\r\n","valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\r\n","                                sampler=valid_sampler, num_workers=num_workers)\r\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\r\n","                                          num_workers=num_workers)\r\n","\r\n","# specify the image classes\r\n","classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', \r\n","           'horse', 'ship', 'truck']"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d792d43ab9c43a98f939dca335479a6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting data/cifar-10-python.tar.gz to data\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DwlAyb9rRo0D"},"source":[""],"execution_count":null,"outputs":[]}]}